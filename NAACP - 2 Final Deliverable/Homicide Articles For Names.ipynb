{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "import csv\n",
    "import sys\n",
    "from spacy.lang.en import English\n",
    "from spacy.matcher import PhraseMatcher\n",
    "import spacy\n",
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = open(\"output_2017_1.txt\", \"r\",encoding=\"utf-8\").readlines()\n",
    "for i in range(len(data_df)):\n",
    "    data_df[i] = str(data_df[i]).replace('[','').replace(']','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "terminology_list = [\"Khisean Desvarieux\",\"Jovani Jeudy\",\"Shawn Peete\",\"Brianna Hardy\",\"Justin Depina\",\"Brendon Tahatdil\",\"Joey Debarros\",\n",
    "                    \"Yanuel Viloria\",\"Thomas Johnson\",\"Dennis Levy\",\"Antwan Stevenson\",\"Lina Bolanos\",\"Richard Field\",\"Servulo Galvao-Antunes\",\n",
    "                    \"Mark Edwards\",\"Kevin Reyes\",\"Corey Reid\",\"Javoni Boyd\",\"Jorrell Browne\",\"Christopher Austin\",\"Michelle Trentor\",\n",
    "                    \"Nathaniel Dix\",\"Anthony Woodbridge\",\"Eric Jackson\",\"Christopher Menard\",\"Dennis Parham\",\"Aice Jackman\",\n",
    "                    \"Andres Cruz\",\"Kenneth Soberanis\",\"John Duggie\",\"Amilton Dossantos\",\"James Gomes\",\"Damien Spencer\",\"Michael Miranda\",\n",
    "                    \"Nakieka Taylor\",\"Alberto Monteiro-Pire\",\"Jerry Gomes\",\"Micaela Gingras\",\"Toney Massey\",\"Carlos Montalvo\",\"Maurice Lyons\",\n",
    "                    \"Xi Van Nguyen\",\"Joshua Briggs\",\"Samuel Pineda-Albizures\",\"David Cole\",\"Gerrod Brown\",\"Brent Stevenson\",\"Torres Nelson\",\n",
    "                    \"Brian Sweeney\",\"Angel Suazo\", \"Natalino Gomes\",\"Jose Montero\",\"Amen Lacy\",\"Dancan Ketter\",\"Phillip Demings\",\"David Charlebois\",\"Kurtis Depina\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Afro Latino\n",
      "[(11356100181062323261, 548, 550), (11356100181062323261, 1920, 1922)]\n",
      "Haitian\n",
      "[(11356100181062323261, 1865, 1866)]\n",
      "[(11356100181062323261, 171, 172)]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "count_F=[]\n",
    "for i in range(len(terminology_list)):\n",
    "    matcher.add(\"Phrase Matching\", None, nlp(terminology_list[i]))\n",
    "    print(nlp(terminology_list[i]))\n",
    "    for j in range(len(data_df)):\n",
    "        doc = nlp(data_df[j])\n",
    "        matches = matcher(doc)\n",
    "        #print(len(matches))\n",
    "        if (len(matches) > 0):\n",
    "            print(matches)\n",
    "            count= count + 1\n",
    "    matcher.remove(\"Phrase Matching\")\n",
    "    count_F.append(count)\n",
    "    count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "print(count_F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Once you get the count from all the sub folder of a year, sum them and manually append the number in the csv file against the name of person for the year you ran the above code.This csv will be further used for sentiment analysis. Create separate csv for different year."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
